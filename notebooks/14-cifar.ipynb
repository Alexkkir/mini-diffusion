{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akkirr/annotated-diffusion\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nan_to_num\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim import Adam\n",
    "\n",
    "from copy import deepcopy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib import *\n",
    "import mylora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(linear_beta_schedule, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"results_folder\": \"PosixPath('results-cifar/1-baseline')\",\n",
       "    \"image_size\": 28,\n",
       "    \"channels\": 3,\n",
       "    \"batch_size\": 128,\n",
       "    \"device\": \"cuda\",\n",
       "    \"checkpoint\": \"checkpoints/4-cifar-colored.pt\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = Settings(\n",
    "    results_folder = Path(\"./results-cifar/1-baseline\"),\n",
    "    image_size = 28,\n",
    "    channels = 3,\n",
    "    batch_size = 128,\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    checkpoint = 'checkpoints/4-cifar-colored.pt'\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.results_folder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"cifar10\")\n",
    "# define image transformations (e.g. using torchvision)\n",
    "transform = Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "# define function\n",
    "def transforms(examples):\n",
    "   examples[\"pixel_values\"] = [transform(image) for image in examples[\"img\"]]\n",
    "   del examples[\"img\"]\n",
    "\n",
    "   return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(transforms).remove_columns(\"label\")\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=settings.batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds()\n",
    "model = Unet(\n",
    "    dim=settings.image_size,\n",
    "    channels=settings.channels,\n",
    "    dim_mults=(1, 2, 4,)\n",
    ")\n",
    "\n",
    "model.to(settings.device)\n",
    "mylora.model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "train(model, optimizer, dataloader, sampler, settings, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gifski created /home/akkirr/annotated-diffusion/results-cifar/1-baseline/sample.gif"
     ]
    }
   ],
   "source": [
    "folder = str(settings.results_folder)\n",
    "! /home/akkirr/.cargo/bin/gifski -o $folder/sample.gif -r 7 $folder/sample-*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), settings.checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train lora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected lora    28 x 2 x 384   in downs.0.2.fn.fn.to_qkv\n",
      "Injected lora   128 x 2 x 28    in downs.0.2.fn.fn.0\n",
      "Injected lora    28 x 2 x 384   in downs.1.2.fn.fn.to_qkv\n",
      "Injected lora   128 x 2 x 28    in downs.1.2.fn.fn.0\n",
      "Injected lora    56 x 2 x 384   in downs.2.2.fn.fn.to_qkv\n",
      "Injected lora   128 x 2 x 56    in downs.2.2.fn.fn.0\n",
      "Injected lora   112 x 2 x 384   in ups.0.2.fn.fn.to_qkv\n",
      "Injected lora   128 x 2 x 112   in ups.0.2.fn.fn.0\n",
      "Injected lora    56 x 2 x 384   in ups.1.2.fn.fn.to_qkv\n",
      "Injected lora   128 x 2 x 56    in ups.1.2.fn.fn.0\n",
      "Injected lora    28 x 2 x 384   in ups.2.2.fn.fn.to_qkv\n",
      "Injected lora   128 x 2 x 28    in ups.2.2.fn.fn.0\n",
      "\n",
      "trainable layers:            24\n",
      "frozen layers:              231\n",
      "total params:           2027747\n"
     ]
    }
   ],
   "source": [
    "set_all_seeds()\n",
    "model = Unet(\n",
    "    dim=settings.image_size,\n",
    "    channels=settings.channels,\n",
    "    dim_mults=(1, 2, 4,)\n",
    ")\n",
    "model.load_state_dict(torch.load(settings.checkpoint))\n",
    "\n",
    "mylora.inject_lora(\n",
    "    model, 2, 0.4,\n",
    "    ['LinearAttention'],\n",
    "    [nn.Conv2d]\n",
    ")\n",
    "model.to(settings.device)\n",
    "\n",
    "mylora.freeze_lora(model)\n",
    "print()\n",
    "mylora.model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "   examples[\"pixel_values\"] = [transform(image.convert('L').convert('RGB')) for image in examples[\"img\"]]\n",
    "   del examples[\"img\"]\n",
    "\n",
    "   return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(transforms).remove_columns(\"label\")\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=settings.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87579e95f37948ef99f8d6120211af22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.021473567932844162\n",
      "Loss: 0.024918898940086365\n",
      "Loss: 0.02179855853319168\n",
      "Loss: 0.024604542180895805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cda1ad9aa7348c5af037ec4a8f169ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020823504775762558\n",
      "Loss: 0.024760788306593895\n",
      "Loss: 0.021668439731001854\n",
      "Loss: 0.02450842224061489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea78938328a418bb9f705b36fb24132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02077310159802437\n",
      "Loss: 0.024704869836568832\n",
      "Loss: 0.02161295711994171\n",
      "Loss: 0.024459373205900192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d0e79dba44443c8c4b32547f28a91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020757650956511497\n",
      "Loss: 0.024674801155924797\n",
      "Loss: 0.021580655127763748\n",
      "Loss: 0.024433648213744164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075a290739ee46408fb350edd8b29f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020747873932123184\n",
      "Loss: 0.024654865264892578\n",
      "Loss: 0.02155657857656479\n",
      "Loss: 0.024414589628577232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dab356740de4e9f99cd65ac9b42e603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020738670602440834\n",
      "Loss: 0.024639418348670006\n",
      "Loss: 0.021537702530622482\n",
      "Loss: 0.024399619549512863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865585e0ea12422aa0fd3668615f641a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020729348063468933\n",
      "Loss: 0.024627139791846275\n",
      "Loss: 0.021523132920265198\n",
      "Loss: 0.02438758686184883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea3f227c99d455e998b454c77663edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020720016211271286\n",
      "Loss: 0.024616152048110962\n",
      "Loss: 0.02151203155517578\n",
      "Loss: 0.024378424510359764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4db6a7e4fa7463b9c50e28cccc521dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02071075513958931\n",
      "Loss: 0.024606024846434593\n",
      "Loss: 0.021503090858459473\n",
      "Loss: 0.024371594190597534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98095a6dafe43d58479c369f653b8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020701846107840538\n",
      "Loss: 0.024596666917204857\n",
      "Loss: 0.021495385095477104\n",
      "Loss: 0.024366270750761032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817cb2aa3fb74002bbfd6081c020c6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "settings.results_folder = Path(\"./results-cifar/2-rank=2_do=0.25\")\n",
    "settings.results_folder.mkdir(exist_ok=True)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "train(model, optimizer, dataloader, sampler, settings, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gifski created /home/akkirr/annotated-diffusion/results-cifar/1-baseline/sample.gif"
     ]
    }
   ],
   "source": [
    "folder = str(settings.results_folder)\n",
    "! /home/akkirr/.cargo/bin/gifski -o $folder/sample.gif -r 7 $folder/sample-*.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
