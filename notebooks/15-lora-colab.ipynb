{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akkirr/annotated-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cloneofsimo/lora.git\n",
      "  Cloning https://github.com/cloneofsimo/lora.git to /place/vartmp/pip-req-build-60oicrtg\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cloneofsimo/lora.git /place/vartmp/pip-req-build-60oicrtg\n",
      "  Resolved https://github.com/cloneofsimo/lora.git to commit bdd51b04c49fa90a88919a19850ec3b4cf3c5ecd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: diffusers>=0.11.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from lora-diffusion==0.1.7) (0.17.1)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from lora-diffusion==0.1.7) (4.30.2)\n",
      "Collecting scipy (from lora-diffusion==0.1.7)\n",
      "  Using cached scipy-1.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "Collecting ftfy (from lora-diffusion==0.1.7)\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting fire (from lora-diffusion==0.1.7)\n",
      "  Using cached fire-0.5.0-py2.py3-none-any.whl\n",
      "Collecting wandb (from lora-diffusion==0.1.7)\n",
      "  Using cached wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: safetensors in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from lora-diffusion==0.1.7) (0.3.1)\n",
      "Collecting opencv-python (from lora-diffusion==0.1.7)\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "Collecting torchvision (from lora-diffusion==0.1.7)\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mediapipe (from lora-diffusion==0.1.7)\n",
      "  Using cached mediapipe-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "Requirement already satisfied: Pillow in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (9.5.0)\n",
      "Requirement already satisfied: filelock in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (0.15.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (6.7.0)\n",
      "Requirement already satisfied: numpy in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (1.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from diffusers>=0.11.0->lora-diffusion==0.1.7) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from transformers>=4.25.1->lora-diffusion==0.1.7) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from transformers>=4.25.1->lora-diffusion==0.1.7) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from transformers>=4.25.1->lora-diffusion==0.1.7) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from transformers>=4.25.1->lora-diffusion==0.1.7) (4.65.0)\n",
      "Requirement already satisfied: six in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from fire->lora-diffusion==0.1.7) (1.16.0)\n",
      "Collecting termcolor (from fire->lora-diffusion==0.1.7)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from ftfy->lora-diffusion==0.1.7) (0.2.6)\n",
      "Collecting absl-py (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting matplotlib (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting opencv-contrib-python (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached opencv_contrib_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.9 MB)\n",
      "Collecting protobuf<4,>=3.11 (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: torch==2.0.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torchvision->lora-diffusion==0.1.7) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (4.6.3)\n",
      "Requirement already satisfied: sympy in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (1.12)\n",
      "Requirement already satisfied: networkx in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch==2.0.1->torchvision->lora-diffusion==0.1.7) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision->lora-diffusion==0.1.7) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision->lora-diffusion==0.1.7) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision->lora-diffusion==0.1.7) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision->lora-diffusion==0.1.7) (16.0.6)\n",
      "Collecting Click!=8.0.0,>=7.0 (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from wandb->lora-diffusion==0.1.7) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached sentry_sdk-1.26.0-py2.py3-none-any.whl (209 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Collecting setproctitle (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting appdirs>=1.4.3 (from wandb->lora-diffusion==0.1.7)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->lora-diffusion==0.1.7)\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: fsspec in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from huggingface-hub>=0.13.2->diffusers>=0.11.0->lora-diffusion==0.1.7) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from requests->diffusers>=0.11.0->lora-diffusion==0.1.7) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from requests->diffusers>=0.11.0->lora-diffusion==0.1.7) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from requests->diffusers>=0.11.0->lora-diffusion==0.1.7) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from requests->diffusers>=0.11.0->lora-diffusion==0.1.7) (2023.5.7)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe->lora-diffusion==0.1.7)\n",
      "  Downloading cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.8/441.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from importlib-metadata->diffusers>=0.11.0->lora-diffusion==0.1.7) (3.15.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached fonttools-4.40.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe->lora-diffusion==0.1.7)\n",
      "  Using cached pyparsing-3.1.0-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from matplotlib->mediapipe->lora-diffusion==0.1.7) (2.8.2)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->lora-diffusion==0.1.7)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->lora-diffusion==0.1.7)\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision->lora-diffusion==0.1.7) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision->lora-diffusion==0.1.7) (1.3.0)\n",
      "Building wheels for collected packages: lora-diffusion\n",
      "  Building wheel for lora-diffusion (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lora-diffusion: filename=lora_diffusion-0.1.7-py3-none-any.whl size=37977 sha256=b528f70d2365ceaf31828bd51d3ac84ab8f772be1f3178a0e3371f744a7b64c3\n",
      "  Stored in directory: /place/vartmp/pip-ephem-wheel-cache-qrsqtuku/wheels/66/ff/e9/63a74dd5353f22e07baad2e2c9be124e339c476767770d4020\n",
      "Successfully built lora-diffusion\n",
      "Installing collected packages: pathtools, flatbuffers, appdirs, termcolor, smmap, setproctitle, sentry-sdk, scipy, pyparsing, pycparser, protobuf, opencv-python, opencv-contrib-python, kiwisolver, ftfy, fonttools, docker-pycreds, cycler, contourpy, Click, attrs, absl-py, matplotlib, gitdb, fire, CFFI, sounddevice, GitPython, wandb, mediapipe, torchvision, lora-diffusion\n",
      "Successfully installed CFFI-1.15.1 Click-8.1.3 GitPython-3.1.31 absl-py-1.4.0 appdirs-1.4.4 attrs-23.1.0 contourpy-1.1.0 cycler-0.11.0 docker-pycreds-0.4.0 fire-0.5.0 flatbuffers-23.5.26 fonttools-4.40.0 ftfy-6.1.1 gitdb-4.0.10 kiwisolver-1.4.4 lora-diffusion-0.1.7 matplotlib-3.7.1 mediapipe-0.10.1 opencv-contrib-python-4.7.0.72 opencv-python-4.7.0.72 pathtools-0.1.2 protobuf-3.20.3 pycparser-2.21 pyparsing-3.1.0 scipy-1.11.0 sentry-sdk-1.26.0 setproctitle-1.3.2 smmap-5.0.0 sounddevice-0.4.6 termcolor-2.3.0 torchvision-0.15.2 wandb-0.15.4\n",
      "Requirement already satisfied: accelerate in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (0.20.3)\n",
      "Requirement already satisfied: bitsandbytes in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (0.39.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from accelerate) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
      "Requirement already satisfied: sympy in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (67.8.0)\n",
      "Requirement already satisfied: wheel in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/cloneofsimo/lora.git\n",
    "!pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# from google.colab import files\n",
    "from tqdm import tqdm\n",
    "\n",
    "PRETRAINED_MODEL=\"runwayml/stable-diffusion-v1-5\" #@param{type: 'string'}\n",
    "PROMPT=\"vase\" #@param{type: 'string'}\n",
    "\n",
    "OUTPUT_DIR=\"\" #@param{type: 'string'}\n",
    "IMAGES_FOLDER_OPTIONAL=\"vaze-gzhel\" #@param{type: 'string'}\n",
    "\n",
    "RESOLUTION=\"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
    "RESOLUTION=int(RESOLUTION)\n",
    "\n",
    "if PRETRAINED_MODEL == \"\":\n",
    "  print('\u001b[1;31mYou should define the pretrained model.')\n",
    "\n",
    "else:\n",
    "  if IMAGES_FOLDER_OPTIONAL==\"\":\n",
    "    INSTANCE_DIR = \"content/data_example\"\n",
    "    if not os.path.exists(str(INSTANCE_DIR)):\n",
    "      %mkdir -p \"$INSTANCE_DIR\"\n",
    "    uploaded = files.upload()\n",
    "    for filename in tqdm(uploaded.keys(), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "        shutil.move(filename, INSTANCE_DIR)\n",
    "  else:\n",
    "    INSTANCE_DIR = IMAGES_FOLDER_OPTIONAL\n",
    "  \n",
    "  if OUTPUT_DIR == \"\":\n",
    "    OUTPUT_DIR = \"../content/output\"\n",
    "  if not os.path.exists(str(OUTPUT_DIR)):\n",
    "    %mkdir -p \"$OUTPUT_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/x86_64-linux-gnu/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/ && echo $LD_LIBRARY_PATH\n",
    "! echo $LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `3`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/accelerator.py:258: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/accelerator.py:258: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/accelerator.py:258: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/accelerator.py:375: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/accelerator.py:375: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/accelerator.py:375: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "Before training: Unet First Layer lora up tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Before training: Unet First Layer lora down tensor([[-0.0078,  0.0838,  0.0561,  ...,  0.0253,  0.0190,  0.0280],\n",
      "        [-0.0168, -0.0093,  0.0865,  ..., -0.0583,  0.0856,  0.0140],\n",
      "        [-0.0192, -0.0908,  0.0859,  ..., -0.0271,  0.0219, -0.0465],\n",
      "        ...,\n",
      "        [ 0.0046, -0.0807,  0.0093,  ..., -0.0005,  0.1286,  0.0719],\n",
      "        [-0.0100,  0.0805,  0.0568,  ..., -0.0274, -0.0442, -0.1199],\n",
      "        [ 0.0316, -0.0495, -0.0506,  ..., -0.0506,  0.0031, -0.0209]])\n",
      "Before training: Unet First Layer lora up tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Before training: Unet First Layer lora down tensor([[-4.5709e-02,  3.7582e-02, -7.8958e-02,  ...,  1.0995e-01,\n",
      "         -7.4420e-02,  1.2563e-02],\n",
      "        [ 1.0738e-01, -4.7259e-02, -3.5425e-02,  ..., -4.1814e-02,\n",
      "         -5.2797e-02, -4.9056e-03],\n",
      "        [ 2.9719e-02,  2.3014e-02, -3.2350e-02,  ..., -1.2131e-01,\n",
      "         -1.1365e-01, -4.4248e-02],\n",
      "        ...,\n",
      "        [ 9.7098e-03, -1.0175e-02,  4.6858e-02,  ...,  3.8965e-02,\n",
      "         -2.4092e-02,  2.9727e-03],\n",
      "        [-5.9190e-02, -1.0032e-04,  6.1435e-03,  ...,  4.4599e-02,\n",
      "         -1.9689e-02, -2.3514e-02],\n",
      "        [-2.1784e-02,  2.3447e-02,  8.5526e-02,  ..., -2.7529e-02,\n",
      "          4.9179e-03, -1.3888e-01]])\n",
      "Before training: Unet First Layer lora up tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Before training: Unet First Layer lora down tensor([[-0.0416,  0.0152, -0.0441,  ...,  0.0207, -0.1458,  0.0014],\n",
      "        [-0.0571, -0.0627,  0.0892,  ..., -0.0533,  0.1822,  0.0124],\n",
      "        [ 0.0242,  0.0823, -0.0592,  ..., -0.0682, -0.0277, -0.0946],\n",
      "        ...,\n",
      "        [-0.0029,  0.0612, -0.0069,  ...,  0.0091, -0.0864, -0.0636],\n",
      "        [ 0.0604, -0.0156, -0.0389,  ..., -0.0398,  0.0669,  0.0702],\n",
      "        [-0.0663,  0.0702,  0.0019,  ..., -0.0347,  0.0189,  0.0371]])\n",
      "Before training: text encoder First Layer lora up tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Before training: text encoder First Layer lora down tensor([[ 0.1006, -0.0281, -0.0103,  ..., -0.0437,  0.0592,  0.0833],\n",
      "        [ 0.0887,  0.0709,  0.0239,  ..., -0.0158,  0.0804, -0.0056],\n",
      "        [-0.1089, -0.0598, -0.0486,  ..., -0.1385,  0.0871,  0.0849],\n",
      "        ...,\n",
      "        [-0.0344, -0.0869, -0.1085,  ..., -0.1086, -0.0063,  0.0777],\n",
      "        [-0.0248,  0.1385, -0.0550,  ...,  0.1581, -0.0154, -0.0186],\n",
      "        [ 0.0527, -0.0874, -0.0339,  ..., -0.0672, -0.0831, -0.0733]])\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/akkirr/miniconda3/envs/lora_colab did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: CUDA runtime path found: /usr/lib/x86_64-linux-gnu/libcudart.so\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n",
      "CUDA SETUP: Loading binary /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n",
      "Before training: text encoder First Layer lora up tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Before training: text encoder First Layer lora down tensor([[-0.0098,  0.0483,  0.0565,  ...,  0.1388,  0.0369, -0.0172],\n",
      "        [ 0.0775, -0.0193, -0.0357,  ...,  0.0487,  0.0705, -0.0086],\n",
      "        [-0.1178, -0.0755,  0.0053,  ..., -0.0004, -0.0377,  0.0047],\n",
      "        ...,\n",
      "        [ 0.1096, -0.0364, -0.0128,  ..., -0.0585,  0.0588,  0.0193],\n",
      "        [ 0.1173, -0.0026, -0.0279,  ...,  0.0025,  0.0499, -0.0742],\n",
      "        [ 0.1284, -0.0285, -0.0154,  ..., -0.0204, -0.0937,  0.0023]])\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/akkirr/miniconda3/envs/lora_colab did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: CUDA runtime path found: /usr/lib/x86_64-linux-gnu/libcudart.so\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n",
      "CUDA SETUP: Loading binary /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n",
      "Before training: text encoder First Layer lora up tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Before training: text encoder First Layer lora down tensor([[ 0.0147,  0.0580, -0.1426,  ...,  0.0094, -0.0588, -0.1514],\n",
      "        [ 0.0238,  0.1118,  0.0088,  ..., -0.0593, -0.0082, -0.0097],\n",
      "        [ 0.0067,  0.0186,  0.0672,  ..., -0.0197, -0.0699, -0.0563],\n",
      "        ...,\n",
      "        [-0.0379, -0.0517, -0.0346,  ..., -0.0444,  0.0152,  0.0349],\n",
      "        [ 0.0025, -0.0479,  0.0126,  ..., -0.0974, -0.0706, -0.0255],\n",
      "        [ 0.0061, -0.0724, -0.0865,  ...,  0.0523,  0.0154, -0.0617]])\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/akkirr/miniconda3/envs/lora_colab did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: CUDA runtime path found: /usr/lib/x86_64-linux-gnu/libcudart.so\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n",
      "CUDA SETUP: Loading binary /home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/configuration_utils.py:195: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/configuration_utils.py:195: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/configuration_utils.py:195: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "***** Running training *****\n",
      "  Num examples = 6\n",
      "  Num batches each epoch = 2\n",
      "  Num Epochs = 150\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 300\n",
      "***** Running training *****\n",
      "  Num examples = 6\n",
      "  Num batches each epoch = 2\n",
      "  Num Epochs = 150\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 300\n",
      "Steps:   0%|                                            | 0/300 [00:00<?, ?it/s]***** Running training *****\n",
      "  Num examples = 6\n",
      "  Num batches each epoch = 2\n",
      "  Num Epochs = 150\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 300\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akkirr/annotated-diffusion/lora/training_scripts/train_lora_dreambooth.py\", line 1008, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akkirr/annotated-diffusion/lora/training_scripts/train_lora_dreambooth.py\", line 1008, in <module>\n",
      "    main(args)\n",
      "  File \"/home/akkirr/annotated-diffusion/lora/training_scripts/train_lora_dreambooth.py\", line 818, in main\n",
      "    main(args)\n",
      "  File \"/home/akkirr/annotated-diffusion/lora/training_scripts/train_lora_dreambooth.py\", line 818, in main\n",
      "    latents = vae.encode(\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/models/vae.py\", line 566, in encode\n",
      "    h = self.encoder(x)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    latents = vae.encode(\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/models/vae.py\", line 566, in encode\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/models/vae.py\", line 130, in forward\n",
      "    sample = self.conv_in(sample)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    h = self.encoder(x)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/models/vae.py\", line 130, in forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR: SetAttribute CUDNN_ATTR_CONVOLUTION_CONV_MODE Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED\n",
      "    sample = self.conv_in(sample)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR: SetAttribute CUDNN_ATTR_CONVOLUTION_CONV_MODE Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akkirr/annotated-diffusion/lora/training_scripts/train_lora_dreambooth.py\", line 1008, in <module>\n",
      "    main(args)\n",
      "  File \"/home/akkirr/annotated-diffusion/lora/training_scripts/train_lora_dreambooth.py\", line 818, in main\n",
      "    latents = vae.encode(\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/models/vae.py\", line 566, in encode\n",
      "    h = self.encoder(x)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/diffusers/models/vae.py\", line 130, in forward\n",
      "    sample = self.conv_in(sample)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR: SetAttribute CUDNN_ATTR_CONVOLUTION_CONV_MODE Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED\n",
      "Steps:   0%|                                            | 0/300 [00:03<?, ?it/s]\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 842994) of binary: /home/akkirr/miniconda3/envs/lora_colab/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 909, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 604, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/akkirr/miniconda3/envs/lora_colab/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "lora/training_scripts/train_lora_dreambooth.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-06-28_14:36:34\n",
      "  host      : iva-gpu.iva.yp-c.yandex.net\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 842995)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-06-28_14:36:34\n",
      "  host      : iva-gpu.iva.yp-c.yandex.net\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 842996)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-06-28_14:36:34\n",
      "  host      : iva-gpu.iva.yp-c.yandex.net\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 842994)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "STEPS = 300 #@param {type:\"slider\", min:0, max:10000, step:10}\n",
    "BATCH_SIZE = 1 #@param {type:\"slider\", min:0, max:128, step:1}\n",
    "FP_16 = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ----\n",
    "#@markdown UNET PARAMS\n",
    "LEARNING_RATE = 3e-4 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown ----\n",
    "TRAIN_TEXT_ENCODER = True #@param {type:\"boolean\"}\n",
    "#@markdown TEXT ENCODER PARAMS\n",
    "LEARNING_RATE_TEXT_ENCODER = 1e-5 #@param {type:\"number\"}\n",
    "\n",
    "NEW_LEARNING_RATE = LEARNING_RATE / BATCH_SIZE\n",
    "NEW_LEARNING_RATE_TEXT_ENCODER = LEARNING_RATE_TEXT_ENCODER / BATCH_SIZE\n",
    "\n",
    "if FP_16:\n",
    "  fp_16_arg = \"fp16\"\n",
    "else:\n",
    "  fp_16_arg = \"no\"\n",
    "\n",
    "if TRAIN_TEXT_ENCODER:\n",
    "  command = (f'accelerate launch lora/training_scripts/train_lora_dreambooth.py '\n",
    "             f'--pretrained_model_name_or_path=\"{PRETRAINED_MODEL}\" '\n",
    "             f'--instance_data_dir=\"{INSTANCE_DIR}\" '\n",
    "             f'--output_dir=\"{OUTPUT_DIR}\" '\n",
    "             f'--instance_prompt=\"{PROMPT}\" '\n",
    "             f'--resolution=512 '\n",
    "             f'--use_8bit_adam '\n",
    "             f'--mixed_precision=\"{fp_16_arg}\" '\n",
    "             f'--train_batch_size=1 '\n",
    "             f'--gradient_accumulation_steps=1 '\n",
    "             f'--learning_rate={NEW_LEARNING_RATE} '\n",
    "             f'--lr_scheduler=\"constant\" '\n",
    "             f'--lr_warmup_steps=0 '\n",
    "             f'--max_train_steps={STEPS} '\n",
    "             f'--train_text_encoder '\n",
    "             f'--lora_rank=16 '\n",
    "             f'--learning_rate_text={NEW_LEARNING_RATE_TEXT_ENCODER} '\n",
    "             )\n",
    "else:\n",
    "  command = (f'accelerate launch lora/training_scripts/train_lora_dreambooth.py '\n",
    "             f'--pretrained_model_name_or_path=\"{PRETRAINED_MODEL}\" '\n",
    "             f'--instance_data_dir=\"{INSTANCE_DIR}\" '\n",
    "             f'--output_dir=\"{OUTPUT_DIR}\" '\n",
    "             f'--instance_prompt=\"{PROMPT}\" '\n",
    "             f'--resolution=512 '\n",
    "             f'--use_8bit_adam '\n",
    "             f'--mixed_precision=\"{fp_16_arg}\" '\n",
    "             f'--train_batch_size=1 '\n",
    "             f'--gradient_accumulation_steps=1 '\n",
    "             f'--learning_rate={NEW_LEARNING_RATE} '\n",
    "             f'--lr_scheduler=\"constant\" '\n",
    "             f'--lr_warmup_steps=0 '\n",
    "             f'--lora_rank=16 '\n",
    "             f'--max_train_steps={STEPS} '\n",
    "             f'--learning_rate_text={NEW_LEARNING_RATE_TEXT_ENCODER}')\n",
    "! rm -rf $INSTANCE_DIR/.ipynb_checkpoints\n",
    "! LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/ CUDA_VISIBLE_DEVICES=4,6,7 {command}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
